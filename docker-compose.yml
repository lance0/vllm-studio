version: "3.9"

services:
  postgres:
    image: postgres:16
    container_name: vllm-studio-postgres
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DB=litellm
    volumes:
      - ./data/postgres:/var/lib/postgresql/data
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  # LiteLLM - API gateway (handles routing, format translation, cost tracking)
  litellm:
    image: ghcr.io/berriai/litellm:main-latest
    container_name: vllm-studio-litellm
    ports:
      - "4100:4000"
    volumes:
      - ./config/litellm.yaml:/app/config.yaml
      - ./config/tool_call_handler.py:/app/tool_call_handler.py
      - ./data:/app/data
    environment:
      - LITELLM_MASTER_KEY=${LITELLM_MASTER_KEY:-sk-master}
      - DATABASE_URL=postgresql://postgres:postgres@vllm-studio-postgres:5432/litellm?connect_timeout=10&pool_pre_ping=true&pool_size=5&max_overflow=10
      - INFERENCE_API_BASE=${INFERENCE_API_BASE:-http://host.docker.internal:8000/v1}
      - INFERENCE_API_KEY=${INFERENCE_API_KEY:-sk-placeholder}
      - PYTHONPATH=/app
    extra_hosts:
      - "host.docker.internal:host-gateway"
    command: ["--config", "/app/config.yaml", "--port", "4000"]
    restart: unless-stopped
    depends_on:
      postgres:
        condition: service_started
    healthcheck:
      test: ["CMD-SHELL", "python -c \"import urllib.request, os; req = urllib.request.Request('http://localhost:4000/health'); req.add_header('Authorization', 'Bearer ' + os.environ.get('LITELLM_MASTER_KEY', 'sk-master')); urllib.request.urlopen(req)\""]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Redis - Caching and rate limiting for LiteLLM
  redis:
    image: redis:7-alpine
    container_name: vllm-studio-redis
    ports:
      - "6379:6379"
    volumes:
      - ./data/redis:/data
    command: redis-server --appendonly yes --save 60 1
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3

  # Prometheus - Time-series metrics collection
  prometheus:
    image: prom/prometheus:latest
    container_name: vllm-studio-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./config/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./data/prometheus:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
      - '--web.enable-lifecycle'
    restart: unless-stopped
    extra_hosts:
      - "host.docker.internal:host-gateway"

  # Frontend - Next.js web UI
  frontend:
    build:
      context: ./frontend
      args:
        NEXT_PUBLIC_API_URL: ""
    container_name: vllm-studio-frontend
    network_mode: host
    volumes:
      - ./data:/app/data
    environment:
      - BACKEND_URL=http://localhost:8080
      - LITELLM_URL=http://localhost:4100
      - LITELLM_MASTER_KEY=${LITELLM_MASTER_KEY:-sk-master}
      - API_KEY=${VLLM_STUDIO_API_KEY:-}
      - NEXT_PUBLIC_LITELLM_URL=${NEXT_PUBLIC_LITELLM_URL:-http://localhost:4100}
      - EXA_API_KEY=${EXA_API_KEY:-}
      - RAG_ENDPOINT=${RAG_ENDPOINT:-http://localhost:3002}
    restart: unless-stopped
